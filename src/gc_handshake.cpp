/*
 *
 *  Multi Process Garbage Collector
 *  Copyright Â© 2016 Hewlett Packard Enterprise Development Company LP.
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU Lesser General Public License as published by
 *  the Free Software Foundation, either version 3 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU Lesser General Public License for more details.
 *
 *  You should have received a copy of the GNU Lesser General Public License
 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
 *
 *  As an exception, the copyright holders of this Library grant you permission
 *  to (i) compile an Application with the Library, and (ii) distribute the 
 *  Application containing code generated by the Library and added to the 
 *  Application during this compilation process under terms of your choice, 
 *  provided you also meet the terms and conditions of the Application license.
 *
 */

#include <thread>
#include <mutex>
#include <cstdlib>
#include <cstring>
#include <memory>
#include <vector>

#include "mpgc/gc.h"
#include "mpgc/write_barrier.h"

namespace mpgc {
  extern void start_gc(Stage);
  extern void atexit_gc_handler();
  extern void assert_current_alloc_list_empty();

  namespace gc_handshake {
    per_process_struct *process_struct = nullptr;
    mark_bitmap *mbitmap = nullptr;

    thread_local thread_struct_handle thread_struct_handles;
    in_memory_thread_struct_list_type thread_struct_list;

     thread_struct_handle::thread_struct_handle() {
       gc_control_block &cb = control_block();
       gc_status expected_status = Signum::sigInit;
       /* We must ensure that handle is initialzed before thread_struct is inserted
        * in the thread_struct_list from where the GC thread can pick it up and send
        * a signal. This ordering ensures that the application thread is ready to
        * receive signals before GC thread can do so.
        * Therefore, we pass a reference to handle in the insert() function and
        * initialize it there after construction.
        */
       thread_struct_list.insert(handle);
       // We must set status_idx only if we haven't received a signal by that time.
       handle->status_idx.compare_exchange_strong(expected_status, process_struct->get_gc_status());
       handle->persist_data->slot = cb.bump_alloc_slots.acquire_slot();
    }

    template <typename Fn, typename ...Args>
    void process_stack(const std::size_t *start,
                       const std::size_t *end,
                       Fn&& func,
                       Args&& ...args) {
      constexpr auto ptr_type_fld = bits::field<special_ptr_type, std::size_t>(0, 2);
      while (start < end) {
        if (base_offset_ptr::is_valid(reinterpret_cast<uint8_t*>(*start))) {
          std::forward<Fn>(func)(offset_ptr<const gc_allocated>(
            reinterpret_cast<const gc_allocated*>(*start)), std::forward<Args>(args)...);
        } else if (base_offset_ptr::could_be_offset_ptr(*start)) {
          offset_ptr<gc_allocated> ptr(ptr_type_fld.replace(*start,
                                                            special_ptr_type::Strong));
          if (ptr.is_valid() && ptr->get_gc_descriptor().is_valid()) {
            weak_gc_ptr<gc_allocated>::clear_sweep_allocated(ptr);
            //func is supposed to filter out weak pointers. That's why we can't reuse ptr.
            std::forward<Fn>(func)(offset_ptr<const gc_allocated>(*start),
                                   std::forward<Args>(args)...);
          }
        }
        start++;
      }
    }

    void process_stack_weak_ptrs(in_memory_thread_struct &thread_struct,
                                 std::size_t *start, std::size_t * const end) {
      gc_control_block &cb = control_block();
      bool clear_signal = false;
      /* We need to make signal clearing conditional as this function may be called while
       * thread is inside lock/write_barrier.
       */
      if (thread_struct.weak_signal == Weak_signal::Working) {
        thread_struct.weak_signal = Weak_signal::InBarrier;
        clear_signal = true;
      }

      for (auto it = thread_struct.on_stack_wp_set.begin();
           it != thread_struct.on_stack_wp_set.end();) {
        if (*it <= start) {
          it = thread_struct.on_stack_wp_set.erase(it);
        } else {
          it++;
        }
      }

      while (start < end) {
        if (base_offset_ptr::could_be_offset_ptr(*start) &&
            base_offset_ptr::is_weak(*start)) {
          offset_ptr<const gc_allocated> ptr(*start);
          if (!weak_gc_ptr<const gc_allocated>::marked_or_sweep_allocated(cb, ptr)) {
            thread_struct.on_stack_wp_set.insert(start);
          }
        }
        start++;
      }
      if (clear_signal) {
        thread_struct.weak_signal = Weak_signal::Working;
      }
    }

 /*   void do_sweep_signal(in_memory_thread_struct &thread_struct) {
      assert(thread_struct.status_idx.load().status() != Signum::sigInit);
      assert(thread_struct.status_idx.load().index() != process_struct->global_list_index());
      assert_current_alloc_list_empty();

      thread_struct.status_idx = gc_status(Signum::sigSweep, 1 - thread_struct.status_idx.load().index());
      thread_struct.local_free_list.clear();
    }*/

    void hdl_sync(Signum sig) {
      in_memory_thread_struct &thread_struct = *thread_struct_handles.handle;
      if (thread_struct.mark_signal_disabled) {
        thread_struct.mark_signal_requested = sig;
      } else if (thread_struct.status_idx.load().status() == Signum::sigInit) {
        thread_struct.status_idx = process_struct->get_gc_status();
      } else {
        assert(thread_struct.status_idx.load().index() == process_struct->global_list_index());
        thread_struct.status_idx = gc_status(sig, thread_struct.status_idx.load().index());
      }
      return;
    }

    void hdl_async() {
      in_memory_thread_struct &thread_struct = *thread_struct_handles.handle;
      Signum sig = thread_struct.status_idx.load().status();
      if (sig == Signum::sigAsync) {
        return;
      }
      void *stack_addr = nullptr;

      if (thread_struct.mark_signal_disabled) {
        thread_struct.mark_signal_requested = Signum::sigAsync;
      } else if (sig == Signum::sigInit) {
        thread_struct.status_idx = process_struct->get_gc_status();
      } else {
        assert(thread_struct.status_idx.load().index() == process_struct->global_list_index());
        process_stack(reinterpret_cast<std::size_t*>(&stack_addr),
                      reinterpret_cast<std::size_t*>(thread_struct.stack_end),
                      mark_gray, thread_struct);

        thread_struct.status_idx = gc_status(Signum::sigAsync, thread_struct.status_idx.load().index());
      }
    }

    void hdl_sweep() {
      in_memory_thread_struct &thread_struct = *thread_struct_handles.handle;
      Signum sig = thread_struct.status_idx.load().status();
      //If we are already set, then just return back.
      if (sig == Signum::sigSweep) {
        assert(thread_struct.status_idx.load().index() == process_struct->global_list_index());
        return;
      }

      if (thread_struct.sweep_signal_disabled) {
        thread_struct.sweep_signal_requested = true;
      } else if (sig == Signum::sigInit) {
        thread_struct.status_idx = process_struct->get_gc_status();
      } else {
        void *stack_addr = nullptr;
        assert(thread_struct.status_idx.load().index() != process_struct->global_list_index());
        assert_current_alloc_list_empty();

        thread_struct.status_idx = gc_status(Signum::sigSweep, 1 - thread_struct.status_idx.load().index());
        process_stack_weak_ptrs(thread_struct,
                                reinterpret_cast<std::size_t*>(&stack_addr),
                                reinterpret_cast<std::size_t*>(thread_struct.stack_end));
        thread_struct.clear_local_allocator = true;
      }
    }

    void hdl_abrt(int sig, siginfo_t *siginfo, void *context) {
      pthread_kill(pthread_self(), SIGSTOP);
    }

    void signal_hdl(int sig, siginfo_t *siginfo, void *context) {
#define SIGNUM_TO_INT(x) static_cast<char>(x)
      switch(siginfo->si_value.sival_int) {
      case SIGNUM_TO_INT(Signum::sigSync1):
       hdl_sync(Signum::sigSync1);
       break;
      case SIGNUM_TO_INT(Signum::sigSync2):
       hdl_sync(Signum::sigSync2);
       break;
      case SIGNUM_TO_INT(Signum::sigAsync):
      case SIGNUM_TO_INT(Signum::sigDeferredAsync):
       hdl_async();
       break;
      case SIGNUM_TO_INT(Signum::sigSweep):
      case SIGNUM_TO_INT(Signum::sigDeferredSweep):
       hdl_sweep();
       break;
      default:
       std::abort();
      }
#undef SIGNUM_TO_INT
    }

    // intiailize1() is only called from mpgc::initialize().  It only be
    // called once.  initialize2() is called once per thread.
    void initialize1() {
      gc_control_block &cb = control_block();
      struct sigaction act;
      std::memset(&act, '\0', sizeof(act));

      /* The SA_SIGINFO flag tells sigaction() to use the sa_sigaction field, not sa_handler. */
      /* The SA_RESTART flag tells sigaction() to restart some blocking system calls, like read(). */
      act.sa_flags = SA_SIGINFO | SA_RESTART;

      /* Use the sa_sigaction field because the handles has two additional parameters */
      act.sa_sigaction = &signal_hdl;
      if (sigaction(SIGRTMIN, &act, NULL) < 0) {
        std::abort();
      }

      if (ruts::env_flag("SUSPEND_ON_ABORT")) {
        act.sa_sigaction = &hdl_abrt;
        if (sigaction(SIGABRT, &act, NULL) < 0) {
          std::abort();
        }
     //   if (sigaction(SIGSEGV, &act, NULL) < 0) {
       //   std::abort();
      //  }
      }

      if (thread_struct_list.head()) {
        /* This code is not required here, but we just keep it to ensure that
         * thread_struct_list is constructed before atexit is called.
         */
        std::abort();
      }
      //Increment to process count and load of status must in the same order as below
      process_struct = cb.process_struct_list.insert();
      mbitmap = &cb.bitmap;

      versioned_pcount_t expected_pcount = cb.total_process_count;
      versioned_pcount_t desired_pcount;
      do {
        desired_pcount.count = expected_pcount.count + 1;
        desired_pcount.version = expected_pcount.version + 1;
      } while (!cb.total_process_count.compare_exchange_weak(expected_pcount, desired_pcount));

      mpgc::Stage stage = cb.stage;
      process_struct->set_gc_status(cb.status.load().data);
      /* If the other processes are in marking1 we enable mutators to sync with gc_thread
       * using optimized mechanism. Otherwise it will be disabled.
       */
      marking_barrier_type local = cb.marking_barrier;
      process_struct->gc_mutator_weak_sync = local._info.index == Barrier_indices::marking1 ? 0 : 1;

      //Create inbound pointer table before GC thread
      inbound_pointers::inbound_table::table(true);
      //Create a GC thread which will do the GC work
      static std::thread gc_thread(start_gc, stage);
      gc_thread.detach();

      std::atexit(atexit_gc_handler);
      std::at_quick_exit(atexit_gc_handler);
    }

    void initialize2() {
      /* We must ensure this is the first (GC-relevant) thread_local
       * that gets created. This is required so that its destruction
       * happens *after* all the other thread_local are destructed.
       */
      if (!thread_struct_handles.handle) {
        std::abort();
      }
    }
  }
}
